import streamlit as st
import os 
import json
import firebase_admin
from firebase_admin import credentials, firestore
from sentence_transformers import SentenceTransformer
import anthropic
import numpy as np
import pandas as pd # ğŸ‘ˆ ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºç”¨ã«pandasã‚’è¿½åŠ 
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. Firestoreæ¥ç¶šã®ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
@st.cache_resource
def setup_firestore():
    if not firebase_admin._apps:
        cert_json_string = st.secrets["firebase"]["cert_json"] 
        cert_dict = json.loads(cert_json_string) 
        cred = credentials.Certificate(cert_dict)
        firebase_admin.initialize_app(cred)
    return firestore.client()

# --- 2. RAGæ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ (ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½ä»˜ã) ---
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

def run_rag_search(query, selected_categories):
    db = setup_firestore()
    model = load_embedding_model()
    
    try:
        query_embedding = model.encode(query)
        
        # å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—
        # NOTE: ãƒ‡ãƒ¼ã‚¿é‡ãŒå¢—ãˆãŸå ´åˆã¯ã€ã“ã“ã§Firestoreã‚¯ã‚¨ãƒªã«ã‚ˆã‚‹äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’æ¤œè¨ã—ã¾ã™
        all_docs = []
        for doc in db.collection("tech_docs").stream():
            data = doc.to_dict()
            data['doc_id'] = doc.id
            # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if data.get('category') in selected_categories:
                all_docs.append(data)

        if not all_docs:
            return "æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ•ã‚£ãƒ«ã‚¿è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        # é¡ä¼¼åº¦è¨ˆç®—
        doc_embeddings = np.array([doc['embedding'] for doc in all_docs])
        similarities = cosine_similarity(query_embedding.reshape(1, -1), doc_embeddings).flatten()
        
        top_indices = np.argsort(similarities)[::-1][:5]
        top_docs = [all_docs[i] for i in top_indices]

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context_text = "\n\n---\n\n".join([doc.get('content', '') for doc in top_docs])
        
        client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])
        
        prompt = f"""
        ã‚ãªãŸã¯å®¶æ—å‘ã‘æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ç›¸è«‡ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æŠ€è¡“æƒ…å ±ã‚’å‚è€ƒã«ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
        ã€æŠ€è¡“æƒ…å ±ã€‘
        {context_text}
        ã€è³ªå•ã€‘
        {query}

        ã€å›ç­”å½¢å¼ã€‘
        - ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã
        - å¿…ãšå…·ä½“çš„ãªæŠ€è¡“åã¨å‡ºå…¸ï¼ˆæ–‡æ›¸ã‚¿ã‚¤ãƒˆãƒ«ï¼‰ã‚’æŒ™ã’ã‚‹
        """
        
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        sources = [doc.get('title', 'ä¸æ˜') for doc in top_docs]
        
        return {
            "answer": response.content[0].text,
            "sources": sources,
            "context": context_text
        }
            
    except Exception as e:
        return f"âŒ RAGæ¤œç´¢å¤±æ•—: ã‚µãƒ¼ãƒãƒ¼å†…éƒ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ({e})"


# --- æ–°æ©Ÿèƒ½: æœªæ¥ã®ååˆºç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ ---
def generate_future_career(topic):
    client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])
    
    prompt = f"""
    You are a visionary career consultant in the year 2035.
    Based on the technology topic: '{topic}', create a fictional, futuristic job profile.
    
    Output format (JSON):
    {{
        "job_title": "Cool sounding job title (English & Japanese)",
        "estimated_salary": "Annual salary in 2035 (JPY)",
        "required_skills": ["Skill 1", "Skill 2", "Skill 3"],
        "mission": "A short, inspiring mission statement for this job."
    }}
    Only output the JSON.
    """
    
    try:
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=500,
            messages=[{"role": "user", "content": prompt}]
        )
        # JSONéƒ¨åˆ†ã ã‘ã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ç°¡æ˜“å‡¦ç†
        import json
        content = response.content[0].text
        # ç°¡æ˜“çš„ã«JSONéƒ¨åˆ†ã‚’æ¢ã™ï¼ˆ{ã‹ã‚‰}ã¾ã§ï¼‰
        json_str = content[content.find("{"):content.rfind("}")+1]
        return json.loads(json_str)
    except Exception as e:
        return None

# --- æ–°æ©Ÿèƒ½: æœªæ¥æ—¥è¨˜ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ ---
def generate_future_diary(topic):
    client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])
    
    prompt = f"""
    You are a novelist writing a 'slice of life' diary entry set in the year 2035.
    The theme is: '{topic}' is now a normal part of everyday life in Japan.
    Write a short, emotional, or funny diary entry (about 300 Japanese characters) from the perspective of an ordinary person (a student, a parent, or a worker).
    Focus on how this technology has changed feelings, scenery, or daily routine.
    
    Output format (JSON):
    {{
        "date": "2035å¹´XæœˆXæ—¥ (Weather)",
        "title": "Catchy Title",
        "author_profile": "Example: '14æ­³ ä¸­å­¦ç”Ÿ' or '45æ­³ ä¸»å©¦'",
        "content": "Diary content..."
    }}
    Only output the JSON.
    """
    
    try:
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        import json
        content = response.content[0].text
        json_str = content[content.find("{"):content.rfind("}")+1]
        return json.loads(json_str)
    except Exception as e:
        return None

# --- æ–°æ©Ÿèƒ½: æ€è€ƒã®æ·±æ˜ã‚Šï¼ˆå±•é–‹ï¼‰ãƒ­ã‚¸ãƒƒã‚¯ ---
def generate_thought_expansion(topic, mode):
    client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])

    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åˆ‡ã‚Šæ›¿ãˆ
    if mode == "abstract":
        instruction = "Identify the superordinate concepts, macro trends, and 'Why it matters' for this technology."
        json_structure = '{"title": "Upper Concepts & Trends", "items": ["Concept 1", "Concept 2", "Why it matters"]}'
    elif mode == "concrete":
        instruction = "List specific applications, products, or industries where this technology is applied in 2030."
        json_structure = '{"title": "Specific Applications (2030)", "items": ["App 1", "App 2", "App 3"]}'
    elif mode == "analogous":
        instruction = "Suggest unexpected combinations with other fields, or analogous technologies. Cross-industry innovation ideas."
        json_structure = '{"title": "Cross-Pollination Ideas", "items": ["Idea 1", "Idea 2", "Idea 3"]}'

    prompt = f"""
    You are a technology strategist. Analyze the topic: '{topic}'.
    {instruction}

    Output format (JSON):
    {json_structure}

    Ensure the content is in Japanese, but the JSON keys remain in English. Only output the JSON.
    """

    try:
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        import json
        content = response.content[0].text
        json_str = content[content.find("{"):content.rfind("}")+1]
        return json.loads(json_str)
    except Exception as e:
        return None

# --- 3. ãƒ‡ãƒ¼ã‚¿å…¨ä»¶å–å¾—é–¢æ•° (ã‚«ã‚¿ãƒ­ã‚°ç”¨) ---
@st.cache_data(ttl=600) # 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_all_data_as_df():
    db = setup_firestore()
    docs_list = []
    for doc in db.collection("tech_docs").stream():
        d = doc.to_dict()
        # è¡¨ç¤ºã«å¿…è¦ãªé …ç›®ã ã‘æŠ½å‡º
        docs_list.append({
            "Title": d.get('title', ''),
            "Category": d.get('category', ''),
            # "Content": d.get('content', '')[:100] + "..." # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å†’é ­
        })
    return pd.DataFrame(docs_list)

# --- 4. èªè¨¼ãƒ­ã‚¸ãƒƒã‚¯ ---
def check_password():
    if st.session_state.get("password_input") == st.secrets.get("APP_PASSWORD"):
        del st.session_state["password_input"] 
        return True
    return False

if "password_correct" not in st.session_state:
    st.session_state["password_correct"] = False

if not st.session_state["password_correct"]:
    st.title("âš”ï¸ CAREER DATA VAULT: AUTH")
    st.markdown("##### æ¬¡ä¸–ä»£æˆ¦ç•¥AIã¸ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ã€èªè¨¼ãŒå¿…è¦ã§ã™ã€‚")
    
    with st.form("login_form"):
        st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="password_input")
        submitted = st.form_submit_button("Login")

        if submitted:
            if check_password():
                st.session_state["password_correct"] = True
                st.rerun() 
            else:
                st.error('ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚')
            
    st.stop() 

# --- 5. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªç”»é¢ (ã‚µã‚¤ãƒ‰ãƒãƒ¼ä»˜) ---

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.title("ğŸ”§ Control Panel")

# ãƒ¢ãƒ¼ãƒ‰é¸æŠ
app_mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰é¸æŠ", ["ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆ (RAG)", "ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚«ã‚¿ãƒ­ã‚°ä¸€è¦§"])

# ã‚½ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
CATEGORY_MAPPING = {
    "Gartner Hype Cycle 2025": "gartner_2025",
    "æ—¥çµŒBP æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰": "nikkei_bp_2025_2035"
}

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ” æ¤œç´¢å¯¾è±¡ã‚½ãƒ¼ã‚¹")
selected_labels = st.sidebar.multiselect(
    "åˆ†æå¯¾è±¡ã‚’é¸æŠ",
    options=list(CATEGORY_MAPPING.keys()),
    default=list(CATEGORY_MAPPING.keys())
)
selected_categories = [CATEGORY_MAPPING[label] for label in selected_labels]


# --- ç”»é¢åˆ†å² ---

if app_mode == "ğŸ’¬ AIãƒãƒ£ãƒƒãƒˆ (RAG)":
    st.title("ğŸ§¬ NEXT-GEN CAREER BRAIN")
    st.markdown("#### **Generate Your Future Roadmap. Your Personal Growth Strategy AI.**")
    st.markdown("---")
    st.markdown("##### **[ACCESS GRANTED]**ã€‚KNOWLEDGE SYSTEM READY FOR QUERY.")
    st.markdown("---")

    # ğŸš¨ ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ1: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    if "rag_result" not in st.session_state:
        st.session_state.rag_result = None
    if "last_query" not in st.session_state:
        st.session_state.last_query = ""

    query = st.text_area("Enter Your Question ...ğŸ¤£æ—¥æœ¬èªã§ãˆãˆã‚ˆğŸ¤£", height=100)

    # æ¤œç´¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ã€çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    if st.button("ğŸ” Research Techs ", type="primary", key='rag_search_button'):
        if not selected_categories:
            st.error("âš ï¸ æ¤œç´¢å¯¾è±¡ã‚½ãƒ¼ã‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¸æŠã—ã¦ãã ã•ã„ã€‚")
        elif query:
            with st.spinner("Analyzing 700 Data Feeds... Standby for Analysis."):
                # æ¤œç´¢å®Ÿè¡Œ
                result = run_rag_search(query, selected_categories)
                # çµæœã¨ã‚¯ã‚¨ãƒªã‚’ä¿å­˜ï¼ˆã“ã‚Œã§ãƒœã‚¿ãƒ³ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¦ã‚‚æ¶ˆãˆãªã„ï¼‰
                st.session_state.rag_result = result
                st.session_state.last_query = query
        else:
            st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # ğŸš¨ ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ2: ä¿å­˜ã•ã‚ŒãŸçµæœãŒã‚ã‚Œã°è¡¨ç¤ºï¼ˆæ¤œç´¢ãƒœã‚¿ãƒ³ã®å¤–ã«å‡ºã™ï¼‰
    # ğŸš¨ ä¿®æ­£ç®‡æ‰€: çµæœè¡¨ç¤ºãƒ–ãƒ­ãƒƒã‚¯å…¨ä½“ã‚’ç½®ãæ›ãˆ
    if st.session_state.rag_result:
        result = st.session_state.rag_result
        
        if isinstance(result, str):
            st.error(result)
        else:
            st.markdown(f"**ğŸ’¡ å›ç­”**\n\n{result['answer']}")
            st.markdown("---")
            st.markdown(f"**ğŸ“š å‚ç…§ã•ã‚ŒãŸè³‡æ–™:** {', '.join(result['sources'])}") 
            
            with st.expander("ğŸ“„ å‚ç…§ã•ã‚ŒãŸåŸæ–‡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç¢ºèªã™ã‚‹"):
                st.code(result['context'], language="markdown")
            # === æ€è€ƒã®æ·±æ˜ã‚Šæ©Ÿèƒ½ã‚¨ãƒªã‚¢ ===
            st.markdown("---")
            st.subheader("ğŸ’¡ Deep Dive & Expansion")
            st.markdown("è¦–ç‚¹ã‚’å¤‰ãˆã¦ã€ã“ã®æŠ€è¡“ã‚’æ·±æ˜ã‚Šã—ã¾ã™ã€‚")
            
            # ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
            if "thought_expansion" not in st.session_state:
                st.session_state.thought_expansion = None
            
            # 3ã¤ã®ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã«
            col_d1, col_d2, col_d3 = st.columns(3)
            
            with col_d1:
                if st.button("â¬†ï¸ æŠ½è±¡åŒ– (ä¸Šä½æ¦‚å¿µ)", key="btn_abstract", use_container_width=True):
                    with st.spinner("Thinking Macro..."):
                        st.session_state.thought_expansion = generate_thought_expansion(st.session_state.last_query, "abstract")
            
            with col_d2:
                if st.button("â¬‡ï¸ å…·ä½“åŒ– (å¿œç”¨ä¾‹)", key="btn_concrete", use_container_width=True):
                    with st.spinner("Thinking Micro..."):
                        st.session_state.thought_expansion = generate_thought_expansion(st.session_state.last_query, "concrete")
            
            with col_d3:
                if st.button("â†”ï¸ æ¨ªå±•é–‹ (é–¢é€£æŠ€è¡“)", key="btn_analogous", use_container_width=True):
                    with st.spinner("Connecting Dots..."):
                        st.session_state.thought_expansion = generate_thought_expansion(st.session_state.last_query, "analogous")

            # æ·±æ˜ã‚Šçµæœã®è¡¨ç¤º
            if st.session_state.thought_expansion:
                data = st.session_state.thought_expansion
                st.info(f"**{data.get('title', 'Analysis Result')}**")
                for item in data.get('items', []):
                    st.write(f"â€¢ {item}")

            # === ã‚¨ãƒ³ã‚¿ãƒ¡æ©Ÿèƒ½ã‚¨ãƒªã‚¢ ===
            st.markdown("---")
            st.subheader("ğŸš€ 2035 Vision Simulation")
            st.markdown("ã“ã®æŠ€è¡“ãŒå®Ÿç¾ã—ãŸæœªæ¥ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚")

            # ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–ï¼ˆãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸçµæœã‚’ä¿æŒã™ã‚‹ãŸã‚ï¼‰
            if "career_card" not in st.session_state:
                st.session_state.career_card = None
            if "future_diary" not in st.session_state:
                st.session_state.future_diary = None

            # ãƒœã‚¿ãƒ³ã‚’2åˆ—ã«é…ç½®
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸƒ æœªæ¥ã®ååˆºã‚’ä½œã‚‹", key="btn_card", use_container_width=True):
                    with st.spinner("Designing Future Career..."):
                        st.session_state.career_card = generate_future_career(st.session_state.last_query)
                        st.session_state.future_diary = None # ç‰‡æ–¹ã ã‘è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«ãƒªã‚»ãƒƒãƒˆ

            with col2:
                if st.button("ğŸ“– æœªæ¥ã®æ—¥è¨˜ã‚’èª­ã‚€", key="btn_diary", use_container_width=True):
                    with st.spinner("Writing Future Story..."):
                        st.session_state.future_diary = generate_future_diary(st.session_state.last_query)
                        st.session_state.career_card = None # ç‰‡æ–¹ã ã‘è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«ãƒªã‚»ãƒƒãƒˆ

            # --- ååˆºã®è¡¨ç¤º ---
            if st.session_state.career_card:
                card = st.session_state.career_card
                st.success("âœ… 2035å¹´ã®ã‚­ãƒ£ãƒªã‚¢äºˆæ¸¬")
                
                # ã‚«ãƒ¼ãƒ‰é¢¨ãƒ‡ã‚¶ã‚¤ãƒ³
                with st.container(border=True):
                    c1, c2 = st.columns([1, 3])
                    with c1:
                        st.image("https://img.icons8.com/fluency/96/future.png", width=70)
                    with c2:
                        st.markdown(f"### {card.get('job_title', 'Future Job')}")
                        st.caption(f"æƒ³å®šå¹´å: {card.get('estimated_salary', '---')}")
                    
                    st.markdown(f"**Mission:** {card.get('mission', '')}")
                    st.markdown("**Required Skills:**")
                    st.write(" ".join([f"`{s}`" for s in card.get('required_skills', [])]))

            # --- æ—¥è¨˜ã®è¡¨ç¤º ---
            if st.session_state.future_diary:
                diary = st.session_state.future_diary
                st.info("âœ… 2035å¹´ã®æ—¥å¸¸ãƒ­ã‚°")
                
                # æ—¥è¨˜é¢¨ãƒ‡ã‚¶ã‚¤ãƒ³
                with st.container(border=True):
                    st.markdown(f"### ğŸ“– {diary.get('title', 'ç„¡é¡Œ')}")
                    st.caption(f"ğŸ“… {diary.get('date', '2035')} | âœï¸ {diary.get('author_profile', 'åŒ¿å')}")
                    st.write(diary.get('content', ''))


elif app_mode == "ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚«ã‚¿ãƒ­ã‚°ä¸€è¦§":
    st.title("ğŸ“š Data Catalog")
    # ... (ã‚«ã‚¿ãƒ­ã‚°è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã¯ãã®ã¾ã¾) ...
    # ã‚‚ã—ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã‚³ãƒ”ãƒšãŒå¿…è¦ãªã‚‰æŒ‡ç¤ºãã ã•ã„
    st.markdown("ç¾åœ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹å…¨æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆã®ä¸€è¦§ã§ã™ã€‚")
    df = get_all_data_as_df()
    df_filtered = df[df['Category'].isin(selected_categories)]
    st.info(f"å…¨ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)} ä»¶ / è¡¨ç¤ºä¸­: {len(df_filtered)} ä»¶")
    st.dataframe(
        df_filtered,
        use_container_width=True,
        hide_index=True,
        column_config={
            "Title": st.column_config.TextColumn("ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«", width="medium"),
            "Category": st.column_config.TextColumn("ã‚«ãƒ†ã‚´ãƒª", width="small"),
        }
    )

# --- ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ ---
st.sidebar.markdown("---")
if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", key='logout_button_sidebar'):
    st.session_state["password_correct"] = False
    st.session_state.rag_result = None # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆæ™‚ã«çµæœã‚‚ã‚¯ãƒªã‚¢
    st.rerun()
