import streamlit as st
import os 
import json
import firebase_admin
from firebase_admin import credentials, firestore
from sentence_transformers import SentenceTransformer
import anthropic
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. FirestoreæŽ¥ç¶šã®ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
@st.cache_resource
def setup_firestore():
    if not firebase_admin._apps:
        try:
            cert_json_string = st.secrets["firebase"]["cert_json"] 
            cert_dict = json.loads(cert_json_string) 
            cred = credentials.Certificate(cert_dict)
            firebase_admin.initialize_app(cred)
        except Exception as e:
            st.error(f"FirestoreæŽ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return None
    return firestore.client()

# --- 2. RAGæ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ ---
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

def run_rag_search(query, selected_categories):
    db = setup_firestore()
    if not db: return "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŽ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    model = load_embedding_model()
    
    try:
        query_embedding = model.encode(query)
        
        all_docs = []
        # tech_docsã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        docs_stream = db.collection("tech_docs").stream()
        
        for doc in docs_stream:
            data = doc.to_dict()
            data['doc_id'] = doc.id
            # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if data.get('category') in selected_categories:
                all_docs.append(data)

        if not all_docs:
            return "æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ•ã‚£ãƒ«ã‚¿è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        # é¡žä¼¼åº¦è¨ˆç®—
        doc_embeddings = np.array([doc['embedding'] for doc in all_docs])
        similarities = cosine_similarity(query_embedding.reshape(1, -1), doc_embeddings).flatten()
        
        top_indices = np.argsort(similarities)[::-1][:5]
        top_docs = [all_docs[i] for i in top_indices]

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        context_text = "\n\n---\n\n".join([doc.get('content', '') for doc in top_docs])
        
        client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])
        
        prompt = f"""
        ã‚ãªãŸã¯å®¶æ—å‘ã‘æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ç›¸è«‡ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æŠ€è¡“æƒ…å ±ã‚’å‚è€ƒã«ã€è³ªå•ã«å›žç­”ã—ã¦ãã ã•ã„ã€‚
        ã€æŠ€è¡“æƒ…å ±ã€‘
        {context_text}
        ã€è³ªå•ã€‘
        {query}

        ã€å›žç­”å½¢å¼ã€‘
        - ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã
        - å¿…ãšå…·ä½“çš„ãªæŠ€è¡“åã¨å‡ºå…¸ï¼ˆæ–‡æ›¸ã‚¿ã‚¤ãƒˆãƒ«ï¼‰ã‚’æŒ™ã’ã‚‹
        """
        
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        sources = [doc.get('title', 'ä¸æ˜Ž') for doc in top_docs]
        
        return {
            "answer": response.content[0].text,
            "sources": sources,
            "context": context_text
        }
            
    except Exception as e:
        return f"âŒ RAGæ¤œç´¢å¤±æ•—: ã‚µãƒ¼ãƒãƒ¼å†…éƒ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ({e})"

# --- ç”ŸæˆAIå…±é€šé–¢æ•° (JSONãƒ‘ãƒ¼ã‚¹å¼·åŒ–ç‰ˆ) ---
def call_claude_json(prompt):
    client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])
    try:
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        content = response.content[0].text
        # JSONéƒ¨åˆ†æŠ½å‡º
        s_idx = content.find("{")
        e_idx = content.rfind("}")
        if s_idx != -1 and e_idx != -1:
            json_str = content[s_idx:e_idx+1]
            return json.loads(json_str)
        else:
            return None
    except Exception as e:
        st.error(f"AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- æ–°æ©Ÿèƒ½: æœªæ¥ã®ååˆº ---
def generate_future_career(topic):
    prompt = f"""
    You are a visionary career consultant in the year 2035.
    Based on the technology topic: '{topic}', create a fictional, futuristic job profile.
    Output format (JSON):
    {{
        "job_title": "Cool sounding job title (English & Japanese)",
        "estimated_salary": "Annual salary in 2035 (JPY)",
        "required_skills": ["Skill 1", "Skill 2", "Skill 3"],
        "mission": "A short, inspiring mission statement."
    }}
    Only output the JSON.
    """
    return call_claude_json(prompt)

# --- æ–°æ©Ÿèƒ½: æœªæ¥æ—¥è¨˜ ---
def generate_future_diary(topic):
    prompt = f"""
    You are a novelist writing a 'slice of life' diary entry set in the year 2035.
    The theme is: '{topic}' is now a normal part of everyday life in Japan.
    Output format (JSON):
    {{
        "date": "2035å¹´XæœˆXæ—¥ (Weather)",
        "title": "Catchy Title",
        "author_profile": "Example: '14æ­³ ä¸­å­¦ç”Ÿ' or '45æ­³ ä¸»å©¦'",
        "content": "Diary content (about 300 Japanese characters)..."
    }}
    Only output the JSON.
    """
    return call_claude_json(prompt)

# --- æ–°æ©Ÿèƒ½: æ€è€ƒã®æ·±æŽ˜ã‚Š ---
def generate_thought_expansion(topic, mode):
    instructions = {
        "abstract": "Identify superordinate concepts, macro trends, and 'Why it matters'.",
        "concrete": "List specific applications, products, or industries in 2030.",
        "analogous": "Suggest unexpected combinations or analogous technologies."
    }
    titles = {
        "abstract": "Upper Concepts & Trends",
        "concrete": "Specific Applications (2030)",
        "analogous": "Cross-Pollination Ideas"
    }
    
    prompt = f"""
    You are a technology strategist. Analyze: '{topic}'.
    {instructions.get(mode, "")}
    Output format (JSON):
    {{
        "title": "{titles.get(mode, 'Analysis')}",
        "items": ["Item 1", "Item 2", "Item 3", "Item 4", "Item 5"]
    }}
    Ensure content is in Japanese. Only output the JSON.
    """
    return call_claude_json(prompt)

# --- æ–°æ©Ÿèƒ½: æŠ€è¡“éšŽå±¤ãƒžãƒƒãƒ— ---
def generate_tech_hierarchy(topic):
    client = anthropic.Anthropic(api_key=st.secrets["CLAUDE_API_KEY"])
    prompt = f"""
    You are a technology taxonomist. Create a hierarchical map for: '{topic}'.
    Output ONLY valid Graphviz DOT code.
    - Use 'digraph G'
    - Use rectangular nodes.
    - No markdown backticks.
    - Labels in Japanese.
    """
    try:
        response = client.messages.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        dot_code = response.content[0].text
        return dot_code.replace("```graphviz", "").replace("```", "").strip()
    except:
        return None

# --- 3. ãƒ‡ãƒ¼ã‚¿å…¨ä»¶å–å¾—é–¢æ•° ---
@st.cache_data(ttl=600)
def get_all_data_as_df():
    db = setup_firestore()
    if not db: return pd.DataFrame()
    
    docs_list = []
    for doc in db.collection("tech_docs").stream():
        d = doc.to_dict()
        docs_list.append({
            "Title": d.get('title', ''),
            "Category": d.get('category', '')
        })
    return pd.DataFrame(docs_list)

# --- 4. èªè¨¼ãƒ­ã‚¸ãƒƒã‚¯ ---
def check_password():
    if st.session_state.get("password_input") == st.secrets.get("APP_PASSWORD"):
        del st.session_state["password_input"] 
        return True
    return False

if "password_correct" not in st.session_state:
    st.session_state["password_correct"] = False

if not st.session_state["password_correct"]:
    st.title("âš”ï¸ CAREER DATA VAULT: AUTH")
    st.markdown("##### æ¬¡ä¸–ä»£æˆ¦ç•¥AIã¸ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ã€èªè¨¼ãŒå¿…è¦ã§ã™ã€‚")
    
    with st.form("login_form"):
        st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="password_input")
        submitted = st.form_submit_button("Login")
        if submitted:
            if check_password():
                st.session_state["password_correct"] = True
                st.rerun() 
            else:
                st.error('ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚')
    st.stop() 

# --- 5. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªç”»é¢ ---

st.sidebar.title("ðŸ”§ Control Panel")
app_mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰é¸æŠž", ["ðŸ’¬ AIãƒãƒ£ãƒƒãƒˆ (RAG)", "ðŸ“š ãƒ‡ãƒ¼ã‚¿ã‚«ã‚¿ãƒ­ã‚°ä¸€è¦§"])

CATEGORY_MAPPING = {
    "Gartner Hype Cycle 2025": "gartner_2025",
    "æ—¥çµŒBP æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰": "nikkei_bp_2025_2035"
}

st.sidebar.markdown("---")
st.sidebar.subheader("ðŸ” æ¤œç´¢å¯¾è±¡ã‚½ãƒ¼ã‚¹")
selected_labels = st.sidebar.multiselect(
    "åˆ†æžå¯¾è±¡ã‚’é¸æŠž",
    options=list(CATEGORY_MAPPING.keys()),
    default=list(CATEGORY_MAPPING.keys())
)
selected_categories = [CATEGORY_MAPPING[label] for label in selected_labels]

if app_mode == "ðŸ’¬ AIãƒãƒ£ãƒƒãƒˆ (RAG)":
    st.title("ðŸ§¬ NEXT-GEN CAREER BRAIN")
    st.markdown("#### **Generate Your Future Roadmap. Your Personal Growth Strategy AI.**")
    st.markdown("---")
    st.markdown("##### **[ACCESS GRANTED]** KNOWLEDGE SYSTEM READY FOR QUERY.")
    
    # --- ã‚·ã‚¹ãƒ†ãƒ ãƒ•ãƒ­ãƒ¼å›³ (ä¿®æ­£ç‰ˆ) ---
    with st.expander("ðŸ”Œ System Architecture (View Flow)"):
        st.graphviz_chart("""
        digraph RAG {
            rankdir=LR;
            node [shape=box, style=filled, fillcolor="#f9f9f9", fontname="Helvetica", fontsize=10];
            edge [fontname="Helvetica", fontsize=8];
    
            User [label="ðŸ‘¨â€ðŸ’» USER\n(Query)", shape=ellipse, fillcolor="#e8f0fe"];
            DB [label="ðŸ“š VECTOR DB\n(700 Tech Reports)", color="blue"];
            AI [label="ðŸ§  GENERATIVE AI\n(Claude 3 Haiku)", color="red", shape=component];
            Output [label="ðŸš€ OUTPUT\n(Future Roadmap)", shape=note, fillcolor="#d4edda"];
    
            User -> DB [label="Semantic Search"];
            DB -> AI [label="Retrieval"];
            User -> AI [label="Context"];
            AI -> Output [label="Generation"];
            
            # æ‹¡å¼µæ©Ÿèƒ½ãƒ•ãƒ­ãƒ¼
            subgraph cluster_ext
